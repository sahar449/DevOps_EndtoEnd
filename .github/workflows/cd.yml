name: CD to EKS

on:
  workflow_run:
    workflows: ["CI Build & Test"]
    types:
      - completed
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  aws_region: us-west-2
  cluster_name: eksdemo-cluster
  repo_name: eksdemo
  vpc_name: eksdemo-vpc
  domain_name: saharbittman.com

jobs:
  cd:
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success') }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.aws_region }}
          role-session-name: github-actions

      - name: Update kubeconfig for EKS
        run: |
          aws eks update-kubeconfig --region ${{ env.aws_region }} --name ${{ env.cluster_name }}
          kubectl get nodes

      - name: Patch aws-auth
        run: |
          cat <<'EOF' > aws-auth.yaml
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: aws-auth
            namespace: kube-system
          data:
            mapUsers: |
              - userarn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_NUMBER }}:user/${{ secrets.AWS_USER }}
                username: ${{ secrets.AWS_USER }}
                groups:
                  - system:masters
          EOF
          kubectl apply -f aws-auth.yaml

      - name: Install / Upgrade ArgoCD Helm Chart
        run: |
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update
          helm upgrade --install argocd argo/argo-cd \
            --namespace argocd \
            --create-namespace \
            --set server.service.type=LoadBalancer \
            --set server.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"="classic"
          kubectl -n argocd rollout status deployment/argocd-server --timeout=3m

      - name: Wait for ArgoCD LoadBalancer
        run: |
          for i in {1..30}; do
            ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)
            if [[ -n "$ARGOCD_SERVER" ]]; then
              echo "ARGOCD_SERVER=$ARGOCD_SERVER" >> $GITHUB_ENV
              break
            fi
            sleep 10
          done
          if [[ -z "$ARGOCD_SERVER" ]]; then
            exit 1
          fi

      - name: Get VPC ID and set environment variables
        run: |
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=${{ env.vpc_name }}" \
            --query "Vpcs[0].VpcId" \
            --output text)
          echo "VPC_ID=$VPC_ID" >> $GITHUB_ENV
          echo "ECR_NAME=${{ secrets.ECR_NAME }}" >> $GITHUB_ENV

      - name: Apply ArgoCD Yamls
        run: |
          envsubst < ArgoCD/externalCharts/infra.yaml | kubectl apply -f -
          envsubst < ArgoCD/myChart/argo.yaml | kubectl apply -f -
          sleep 10
          kubectl get applications -n argocd

      - name: Apply Flask App
        run: |
          cd ArgoCD/myChart
          kubectl apply -f .

      - name: Smoke Test Application
        run: |
          echo "Running smoke test on https://www.saharbittman.com ..."
          for i in $(seq 1 30); do
            STATUS_CODE=$(curl -s -o /dev/null -w "%{http_code}" https://www.saharbittman.com || true)
            if [ "$STATUS_CODE" = "200" ]; then
              echo "✅ Smoke test passed."
              exit 0
            fi
            echo "⚠️ Attempt $i failed — HTTP status: $STATUS_CODE"
            sleep 15
          done
          echo "❌ Smoke test failed!"
          exit 1

  destroy-on-failure:
    needs: cd
    if: ${{ failure() }}
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.aws_region }}
          role-session-name: github-actions

      - name: Update kubeconfig for EKS
        run: |
          aws eks update-kubeconfig --region ${{ env.aws_region }} --name ${{ env.cluster_name }}

      - name: Destroy ArgoCD and Apps on Failure
        run: |
          kubectl get applications.argoproj.io -n argocd -o name 2>/dev/null | \
            xargs -r -I {} kubectl patch {} -n argocd -p '{"metadata":{"finalizers":[]}}' --type=merge || true
          kubectl get applicationsets.argoproj.io -n argocd -o name 2>/dev/null | \
            xargs -r -I {} kubectl patch {} -n argocd -p '{"metadata":{"finalizers":[]}}' --type=merge || true
          kubectl get ingress -A -o name 2>/dev/null | \
            xargs -r -I {} kubectl patch {} -p '{"metadata":{"finalizers":[]}}' --type=merge || true
          kubectl delete applications.argoproj.io --all -n argocd --timeout=30s || true
          kubectl delete applicationsets.argoproj.io --all -n argocd --timeout=30s || true
          helm uninstall argocd -n argocd --wait --timeout=2m || true

      - name: Cleanup ALBs and Target Groups
        run: |
          echo "Cleaning up AWS ALBs and Target Groups..."
          export AWS_REGION=${{ env.aws_region }}

          for lb_arn in $(aws elbv2 describe-load-balancers --region $AWS_REGION --query 'LoadBalancers[?starts_with(LoadBalancerName, `argocd`)].LoadBalancerArn' --output text); do
            echo "Deleting Load Balancer $lb_arn"
            aws elbv2 delete-load-balancer --region $AWS_REGION --load-balancer-arn $lb_arn || true
          done

          for tg_arn in $(aws elbv2 describe-target-groups --region $AWS_REGION --query 'TargetGroups[?starts_with(TargetGroupName, `argocd`)].TargetGroupArn' --output text); do
            echo "Deleting Target Group $tg_arn"
            aws elbv2 delete-target-group --region $AWS_REGION --target-group-arn $tg_arn || true
          done

          echo "✅ AWS ALBs and Target Groups cleanup completed."
